# -*- coding: utf-8 -*-
"""model_building.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FDOBlFNqzH5hzR4RSgUHxpPZJZDSegmR
"""

#importing libraries
from re import A
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#loading the eda_data csv file
df = pd.read_csv("eda_data.csv")
df.head()

"""## choose relevant columns"""

df.columns

df_model = df[['avg_salary','Rating','Size','Type of ownership', 'Industry', 'Sector', 'Revenue',
             'num_comp','hourly', 'employer_provided','state_job', 'same_state', 
             'company_age','python_yn','r_studio_yn', 'spark_yn', 'aws_yn',
             'excel_yn', 'simplified_job','simplified_seniority', 'desc_length']]

"""## get dummy data (so e.g. like analyst will get a specific col and when anaylst value =1 when it appears in that col)"""

df_dummy = pd.get_dummies(df_model)
df_dummy.head()

"""## train -test split"""

x = df_dummy.iloc[:,1:]
# print(x)
y = df_dummy.avg_salary.values
print(y)

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test  = train_test_split(x,y,test_size=0.2,random_state = 42)

"""## Implementing Linear Regression"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score  #takes sample dataset and validation set and runs it on model and checks whether it generalizes it or not {mini train-test set},baseline on whihc we're gonna evaluate our model on
lm = LinearRegression()
lm.fit(X_train,y_train)

np.mean(cross_val_score(lm,X_train,y_train,scoring='neg_mean_absolute_error',cv=3))
#here we're talking about how it is difficiult to get good values from sparse matrix of multi linear regression model;due to limited data so let's check with lasso model as it normalizes the data

"""## Lasso regression"""

#alpha-- normalization, so inc in alpha value more smoother the data
from sklearn import linear_model
lasso = linear_model.Lasso(alpha=0.13)
lasso.fit(X_train,y_train)

np.mean(cross_val_score(lasso,X_train,y_train,scoring='neg_mean_absolute_error',cv=3))

#trying different values of alpha to check which is best
alpha = []
error = []
for i in range(1,100):
  alpha.append(i/100)
  lasso = linear_model.Lasso(alpha=(i/100))
  error.append(np.mean(cross_val_score(lasso,X_train,y_train,cv = 3,scoring='neg_mean_absolute_error')))

plt.plot(alpha,error)

np.argmax(error)
error[12]

"""Another method to find max value of alpha by converting to tuple"""

#so finding the max value of alpha from graph
err = tuple(zip(alpha,error))
#convert to df
df_err = pd.DataFrame(err,columns=['alpha','error'])  #to attain max value
df_err[df_err.error == max(df_err.error)]

"""## Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()

#checking cross_val_score
np.mean(cross_val_score(rf,X_train,y_train,scoring = 'neg_mean_absolute_error',cv = 3))

"""## Tuning the models using GridSearchCV"""

#so gridsearchcv tune all the models and provides the one as o/p which shows best results
from sklearn.model_selection import GridSearchCV
parameters = {'n_estimators':range(10,300,10), 'criterion':('mse','mae'),'max_features':("auto", "sqrt", "log2")}
gs = GridSearchCV(rf,parameters,scoring='neg_mean_absolute_error',cv=3)
gs.fit(X_train,y_train)

gs.best_score_

gs.best_estimator_

"""## Using Ridge Regression"""

from sklearn.linear_model import Ridge
ridge= Ridge(alpha=0.99)
ridge.fit(X_train,y_train)
np.mean(cross_val_score(ridge, X_train, y_train, scoring='neg_mean_absolute_error', cv=3))

alpha = []
error = []
for i in range(1,100):
  alpha.append(i/100)
  ridge = linear_model.Ridge(alpha=(i/100))
  error.append(np.mean(cross_val_score(ridge,X_train,y_train,cv = 3,scoring='neg_mean_absolute_error')))

plt.plot(alpha,error)

#so finding the max value of alpha from graph
errer = tuple(zip(alpha,error))
#convert to df
df_errer = pd.DataFrame(errer,columns=['alpha','error'])  #to attain max value
df_errer[df_errer.error == max(df_errer.error)]

"""### Test ensembles"""

t_pred_lm = lm.predict(X_test)
t_pred_lasso = lasso.predict(X_test)
t_pred_ridge = ridge.predict(X_test)
t_pred_rf = gs.best_estimator_.predict(X_test)

from sklearn.metrics import mean_absolute_error as mae
mae(y_test,t_pred_lm)

mae(y_test,t_pred_lasso)

mae(y_test,t_pred_rf)

mae(y_test,t_pred_ridge)

"""Averaging the predictions made by the weak classifiers and voted Random Forest regressor to be proving better resukts than others. Moreover, averaging the predictions of the models and taking a pick."""

#this seems to be not working for us at all
mae(y_test,(t_pred_lm + t_pred_ridge)/2)

#this seems to be not working for us at all
mae(y_test,(t_pred_lm + t_pred_rf)/2)

mae(y_test,(t_pred_ridge + t_pred_lasso)/2)

#taking average optimal weights of the model rf and lasso as linear reg is not working for us
mae(y_test,(t_pred_lasso + t_pred_rf)/2)

mae(y_test,(t_pred_ridge + t_pred_rf)/2)



# Creating a Flask API
import pickle
pickl = {'model': gs.best_estimator_}
pickle.dump( pickl, open( 'model_file' + ".p", "wb" ))
file_name = "model_file.p"
with open(file_name, 'rb') as pickled:
    data = pickle.load(pickled)
    model = data['model']
a = model.predict(X_test.iloc[1,:].values.reshape(1,-1))
print(a)

print(list(X_test.iloc[1,:]))